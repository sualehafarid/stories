# stories

Using the Hippocorpus dataset developed at Microsoft Research through the AllenAI Institute, I explore whether linguistic cues that distinguish imagined from recalled human experiences can also help detect hallucinated text in large language models (LLMs). The hypothesis is that imagined human stories share stylistic and cognitive features, such as abstraction, modality, and reduced concreteness, with model generated hallucinations.

Dataset source: https://huggingface.co/datasets/allenai/hippocorpus

Dataset paper: https://aclanthology.org/2020.acl-main.178.pdf
